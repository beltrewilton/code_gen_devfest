{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, k = 10, 10\n",
    "\n",
    "# This way we can generate a rank-deficient matrix\n",
    "W_rank = 2\n",
    "W = torch.randn(d, W_rank) @ torch.randn(W_rank, k)\n",
    "pd.DataFrame(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the rank of the matrix W\n",
    "\n",
    "W_rank = np.linalg.matrix_rank(W)\n",
    "print(f\"Rank of matrix W: {W_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the SVD of the W matrix\n",
    "Perform SVD on ${W = U*V*S^T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.svd(W)\n",
    "\n",
    "# For rank-r factorization, keep only the first r singular values (and corresponding columns of U and V)\n",
    "U_r = U[: , :W_rank]\n",
    "S_r = torch.diag(S[:W_rank])\n",
    "V_r = V[:, :W_rank].t() # Transpose\n",
    "\n",
    "\n",
    "# Compute C = U_r * S_r and R = V_r\n",
    "B = U_r @ S_r\n",
    "A = V_r\n",
    "print(f\"Shape of B: {B.shape}\\nShape of A: {A.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the same input, check the output using the original W matrix and the matrices resulting from the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random bias and input\n",
    "bias = torch.randn(d)\n",
    "x = torch.randn(k)\n",
    "\n",
    "# Compute y = Wx + b\n",
    "y = W @ x + bias\n",
    "y_prime = (B @ A) @ x + bias\n",
    "\n",
    "print(f\"Original y usgin W:\\n{y}\\n\")\n",
    "print(f\"y usgin BA:\\n{y_prime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total parameters of W: {W.nelement()}\")\n",
    "print(f\"Total parameters of b and A: {B.nelement() + A.nelement()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments)\n",
    "\n",
    "device = \"mps\"\n",
    "weights_path: str = \"./weights\"\n",
    "tokeniz_path: str = \"./tokenizer\"\n",
    "datasets_path: str = \"./dataset\"\n",
    "huggingface_dataset_name: str = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name, cache_dir=datasets_path)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, torch_dtype=torch.float32, cache_dir=weights_path\n",
    ")  # bfloat16\n",
    "original_model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=tokeniz_path)\n",
    "\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))\n",
    "\n",
    "\n",
    "index = 200\n",
    "\n",
    "dialogue = dataset[\"test\"][index][\"dialogue\"]\n",
    "summary = dataset[\"test\"][index][\"summary\"]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0],\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "mbpp = 'https://raw.githubusercontent.com/google-research/google-research/master/mbpp/sanitized-mbpp.json'\n",
    "\n",
    "\n",
    "df = pd.read_json(mbpp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>code</th>\n",
       "      <th>test_imports</th>\n",
       "      <th>test_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>2</td>\n",
       "      <td>Write a function to find the shared elements f...</td>\n",
       "      <td>def similar_elements(test_tup1, test_tup2):\\n ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert set(similar_elements((3, 4, 5, 6),(5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>3</td>\n",
       "      <td>Write a python function to identify non-prime ...</td>\n",
       "      <td>import math\\ndef is_not_prime(n):\\n    result ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert is_not_prime(2) == False, assert is_no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>4</td>\n",
       "      <td>Write a function to find the n largest integer...</td>\n",
       "      <td>import heapq as hq\\ndef heap_queue_largest(num...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert heap_queue_largest( [25, 35, 22, 85, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>6</td>\n",
       "      <td>Write a python function to check whether the t...</td>\n",
       "      <td>def is_Power_Of_Two (x): \\n    return x and (n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert differ_At_One_Bit_Pos(13,9) == True, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>7</td>\n",
       "      <td>Write a function to find all words which are a...</td>\n",
       "      <td>import re\\ndef find_char_long(text):\\n  return...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert set(find_char_long('Please move back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>8</td>\n",
       "      <td>Write a function to find squares of individual...</td>\n",
       "      <td>def square_nums(nums):\\n square_nums = list(ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert square_nums([1, 2, 3, 4, 5, 6, 7, 8, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>9</td>\n",
       "      <td>Write a python function to find the minimum nu...</td>\n",
       "      <td>def find_Rotations(str): \\n    tmp = str + str...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert find_Rotations(\"aaaa\") == 1, assert fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>11</td>\n",
       "      <td>Write a python function to remove first and la...</td>\n",
       "      <td>def remove_Occ(s,ch): \\n    for i in range(len...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert remove_Occ(\"hello\",\"l\") == \"heo\", asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>12</td>\n",
       "      <td>Write a function to sort a given matrix in asc...</td>\n",
       "      <td>def sort_matrix(M):\\n    result = sorted(M, ke...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert sort_matrix([[1, 2, 3], [2, 4, 5], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benchmark Questions Verification V2.ipynb</td>\n",
       "      <td>14</td>\n",
       "      <td>Write a python function to find the volume of ...</td>\n",
       "      <td>def find_Volume(l,b,h) : \\n    return ((l * b ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[assert find_Volume(10,8,6) == 240, assert fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 source_file  task_id  \\\n",
       "0  Benchmark Questions Verification V2.ipynb        2   \n",
       "1  Benchmark Questions Verification V2.ipynb        3   \n",
       "2  Benchmark Questions Verification V2.ipynb        4   \n",
       "3  Benchmark Questions Verification V2.ipynb        6   \n",
       "4  Benchmark Questions Verification V2.ipynb        7   \n",
       "5  Benchmark Questions Verification V2.ipynb        8   \n",
       "6  Benchmark Questions Verification V2.ipynb        9   \n",
       "7  Benchmark Questions Verification V2.ipynb       11   \n",
       "8  Benchmark Questions Verification V2.ipynb       12   \n",
       "9  Benchmark Questions Verification V2.ipynb       14   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Write a function to find the shared elements f...   \n",
       "1  Write a python function to identify non-prime ...   \n",
       "2  Write a function to find the n largest integer...   \n",
       "3  Write a python function to check whether the t...   \n",
       "4  Write a function to find all words which are a...   \n",
       "5  Write a function to find squares of individual...   \n",
       "6  Write a python function to find the minimum nu...   \n",
       "7  Write a python function to remove first and la...   \n",
       "8  Write a function to sort a given matrix in asc...   \n",
       "9  Write a python function to find the volume of ...   \n",
       "\n",
       "                                                code test_imports  \\\n",
       "0  def similar_elements(test_tup1, test_tup2):\\n ...           []   \n",
       "1  import math\\ndef is_not_prime(n):\\n    result ...           []   \n",
       "2  import heapq as hq\\ndef heap_queue_largest(num...           []   \n",
       "3  def is_Power_Of_Two (x): \\n    return x and (n...           []   \n",
       "4  import re\\ndef find_char_long(text):\\n  return...           []   \n",
       "5  def square_nums(nums):\\n square_nums = list(ma...           []   \n",
       "6  def find_Rotations(str): \\n    tmp = str + str...           []   \n",
       "7  def remove_Occ(s,ch): \\n    for i in range(len...           []   \n",
       "8  def sort_matrix(M):\\n    result = sorted(M, ke...           []   \n",
       "9  def find_Volume(l,b,h) : \\n    return ((l * b ...           []   \n",
       "\n",
       "                                           test_list  \n",
       "0  [assert set(similar_elements((3, 4, 5, 6),(5, ...  \n",
       "1  [assert is_not_prime(2) == False, assert is_no...  \n",
       "2  [assert heap_queue_largest( [25, 35, 22, 85, 1...  \n",
       "3  [assert differ_At_One_Bit_Pos(13,9) == True, a...  \n",
       "4  [assert set(find_char_long('Please move back t...  \n",
       "5  [assert square_nums([1, 2, 3, 4, 5, 6, 7, 8, 9...  \n",
       "6  [assert find_Rotations(\"aaaa\") == 1, assert fi...  \n",
       "7  [assert remove_Occ(\"hello\",\"l\") == \"heo\", asse...  \n",
       "8  [assert sort_matrix([[1, 2, 3], [2, 4, 5], [1,...  \n",
       "9  [assert find_Volume(10,8,6) == 240, assert fin...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWILTON\\n\\n### Response:'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_task(instruction):\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_no_input\": (\n",
    "                \"Below is an instruction that describes a task. \"\n",
    "                \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "            ),\n",
    "        }\n",
    "        return PROMPT_DICT['prompt_no_input']\n",
    "\n",
    "format_task(\"WILTON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
       "        num_rows: 251820\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
       "        num_rows: 13914\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
       "        num_rows: 14918\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('code_x_glue_ct_code_to_text', 'python')\n",
    "ds\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_gen_devfest_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
